{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-30T09:09:03.189201Z","iopub.execute_input":"2023-06-30T09:09:03.189918Z","iopub.status.idle":"2023-06-30T09:09:03.210813Z","shell.execute_reply.started":"2023-06-30T09:09:03.189884Z","shell.execute_reply":"2023-06-30T09:09:03.209700Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/epochx2/checkpoint.pth_x2.tar\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport random\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport torchvision.transforms.functional as F\nimport torch\nfrom torch import nn\nimport time\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:03.215252Z","iopub.execute_input":"2023-06-30T09:09:03.215586Z","iopub.status.idle":"2023-06-30T09:09:08.388073Z","shell.execute_reply.started":"2023-06-30T09:09:03.215560Z","shell.execute_reply":"2023-06-30T09:09:08.385929Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom progressbar import ProgressBar","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:08.393666Z","iopub.execute_input":"2023-06-30T09:09:08.396292Z","iopub.status.idle":"2023-06-30T09:09:08.430922Z","shell.execute_reply.started":"2023-06-30T09:09:08.396255Z","shell.execute_reply":"2023-06-30T09:09:08.429991Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"try:\n    import accimage\nexcept:\n    accimage = None\n\n\ndef _is_pil_image(img):\n    if accimage is not None:\n        return isinstance(img, (Image.Image, accimage.Image))\n    else:\n        return isinstance(img, Image.Image)\n\n\ndef _is_tensor_image(img):\n    return torch.is_tensor(img) and img.ndimension() == 3\n\n\ndef _is_numpy_image(img):\n    return isinstance(img, np.ndarray) and (img.ndim in {2, 3})\n\n\ndef to_tensor(pic):\n    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n\n    See ``ToTensor`` for more details.\n\n    Args:\n        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n\n    Returns:\n        Tensor: Converted image.\n    \"\"\"\n    if not(_is_pil_image(pic) or _is_numpy_image(pic)):\n        raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\n\n    if isinstance(pic, np.ndarray):\n        # handle numpy array\n        img = torch.from_numpy(pic.transpose((2, 0, 1)))\n        # backward compatibility\n        if isinstance(img, torch.ByteTensor):\n            return img.float().div(255)\n        else:\n            return img\n\n    if accimage is not None and isinstance(pic, accimage.Image):\n        nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)\n        pic.copyto(nppic)\n        return torch.from_numpy(nppic)\n\n    # handle PIL Image\n    if pic.mode == 'I':\n        img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n    elif pic.mode == 'I;16':\n        img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n    elif pic.mode == 'F':\n        img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n    elif pic.mode == '1':\n        img = 255 * torch.from_numpy(np.array(pic, np.uint8, copy=False))\n    else:\n        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n    # PIL image mode: L, P, I, F, RGB, YCbCr, RGBA, CMYK\n    if pic.mode == 'YCbCr':\n        nchannel = 3\n    elif pic.mode == 'I;16':\n        nchannel = 1\n    else:\n        nchannel = len(pic.mode)\n    img = img.view(pic.size[1], pic.size[0], nchannel)\n    # put it from HWC to CHW format\n    # yikes, this transpose takes 80% of the loading time/CPU\n    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n    if isinstance(img, torch.ByteTensor):\n        return img.float().div(255)\n    else:\n        return img\n\n\ndef normalize(tensor, mean, std):\n    \"\"\"Normalize a tensor image with mean and standard deviation.\n\n    See ``Normalize`` for more details.\n\n    Args:\n        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        mean (sequence): Sequence of means for each channel.\n        std (sequence): Sequence of standard deviations for each channely.\n\n    Returns:\n        Tensor: Normalized Tensor image.\n    \"\"\"\n    if not _is_tensor_image(tensor):\n        raise TypeError('tensor is not a torch image.')\n    # TODO: make efficient\n    for t, m, s in zip(tensor, mean, std):\n        t.sub_(m).div_(s)\n    return tensor","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-06-30T09:09:08.435715Z","iopub.execute_input":"2023-06-30T09:09:08.438074Z","iopub.status.idle":"2023-06-30T09:09:08.466144Z","shell.execute_reply.started":"2023-06-30T09:09:08.438032Z","shell.execute_reply":"2023-06-30T09:09:08.464808Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport random\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\n\nfrom torch.utils.data import Dataset\nfrom torchvision.transforms import transforms","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:08.469087Z","iopub.execute_input":"2023-06-30T09:09:08.469527Z","iopub.status.idle":"2023-06-30T09:09:08.647277Z","shell.execute_reply.started":"2023-06-30T09:09:08.469443Z","shell.execute_reply":"2023-06-30T09:09:08.644403Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Utils ","metadata":{}},{"cell_type":"code","source":"def get_scale_from_dataset(dataset):\n    scale = None\n    if len(dataset) > 0:\n        lr = Image.open(dataset[0]['lr'])\n        hr = Image.open(dataset[0]['hr'])\n        dim1 = round(hr.width / lr.width)\n        dim2 = round(hr.height / lr.height)\n        scale = max(dim1, dim2)\n    return scale\n\n\ndef get_scale(lr, hr):\n    dim1 = round(hr.width / lr.width)\n    dim2 = round(hr.height / lr.height)\n    scale = max(dim1, dim2)\n    return scale\n\n\ndef resize_image(lr_image, hr_image, scale=None):\n    if scale is None:\n        scale = get_scale(lr_image, hr_image)\n    if lr_image.width * scale != hr_image.width or lr_image.height * scale != hr_image.height:\n        hr_width = lr_image.width * scale\n        hr_height = lr_image.height * scale\n        return hr_image.resize((hr_width, hr_height), resample=Image.BICUBIC)\n    return hr_image","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:08.649054Z","iopub.execute_input":"2023-06-30T09:09:08.649734Z","iopub.status.idle":"2023-06-30T09:09:08.671885Z","shell.execute_reply.started":"2023-06-30T09:09:08.649699Z","shell.execute_reply":"2023-06-30T09:09:08.670516Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class EvalDataset(Dataset):\n    def __init__(self, dataset, transform = None):\n        super(EvalDataset, self).__init__()\n        self.dataset = dataset\n        self.scale = get_scale_from_dataset(dataset)\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        lr_image = Image.open(self.dataset[idx]['lr']).convert('RGB')\n        hr_image = resize_image(lr_image, Image.open(self.dataset[idx]['hr']).convert('RGB'), scale=self.scale)\n        lr = np.array(lr_image)\n        hr = np.array(hr_image)\n        lr = lr.astype(np.float32).transpose([2, 0, 1]) / 255\n        hr = hr.astype(np.float32).transpose([2, 0, 1]) / 255\n        if self.transform:\n            lr, hr = self.transform(lr, hr)\n            # label = self.transform(label)\n\n        return lr, hr\n\n    def __len__(self):\n        return len(self.dataset)\n    \n    \nclass TrainDataset(Dataset):\n    def __init__(self, dataset, transform = None, patch_size = 64):\n        super(TrainDataset, self).__init__()\n        self.dataset = dataset\n        self.patch_size = patch_size\n        self.scale = get_scale_from_dataset(dataset)\n        self.transform = transform\n    \n    @staticmethod\n    def random_crop(lr, hr, size, scale):\n        lr_left = random.randint(0, lr.shape[1] - size)\n        lr_right = lr_left + size\n        lr_top = random.randint(0, lr.shape[0] - size)\n        lr_bottom = lr_top + size\n        hr_left = lr_left * scale\n        hr_right = lr_right * scale\n        hr_top = lr_top * scale\n        hr_bottom = lr_bottom * scale\n        lr = lr[lr_top:lr_bottom, lr_left:lr_right]\n        hr = hr[hr_top:hr_bottom, hr_left:hr_right]\n        return lr, hr\n\n    @staticmethod\n    def random_horizontal_flip(lr, hr):\n        if random.random() < 0.5:\n            lr = lr[:, ::-1, :].copy()\n            hr = hr[:, ::-1, :].copy()\n        return lr, hr\n\n    @staticmethod\n    def random_vertical_flip(lr, hr):\n        if random.random() < 0.5:\n            lr = lr[::-1, :, :].copy()\n            hr = hr[::-1, :, :].copy()\n        return lr, hr\n\n    @staticmethod\n    def random_rotate_90(lr, hr):\n        if random.random() < 0.5:\n            lr = np.rot90(lr, axes=(1, 0)).copy()\n            hr = np.rot90(hr, axes=(1, 0)).copy()\n        return lr, hr\n\n    def __getitem__(self, idx):\n        lr_image = Image.open(self.dataset[idx]['lr']).convert('RGB')\n        hr_image = resize_image(lr_image, Image.open(self.dataset[idx]['hr']).convert('RGB'), scale=self.scale)\n        lr = np.array(lr_image)\n        hr = np.array(hr_image)\n        lr, hr = self.random_crop(lr, hr, self.patch_size, self.scale)\n        lr, hr = self.random_horizontal_flip(lr, hr)\n        lr, hr = self.random_vertical_flip(lr, hr)\n        lr, hr = self.random_rotate_90(lr, hr)\n        lr = lr.astype(np.float32).transpose([2, 0, 1]) / 255\n        hr = hr.astype(np.float32).transpose([2, 0, 1]) / 255\n        \n        if self.transform:\n            lr, hr = self.transform(lr, hr)\n\n        return lr, hr\n\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:08.677592Z","iopub.execute_input":"2023-06-30T09:09:08.678088Z","iopub.status.idle":"2023-06-30T09:09:08.714066Z","shell.execute_reply.started":"2023-06-30T09:09:08.678040Z","shell.execute_reply":"2023-06-30T09:09:08.712139Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install super_image","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:08.715503Z","iopub.execute_input":"2023-06-30T09:09:08.715847Z","iopub.status.idle":"2023-06-30T09:09:22.219324Z","shell.execute_reply.started":"2023-06-30T09:09:08.715816Z","shell.execute_reply":"2023-06-30T09:09:22.218187Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting super_image\n  Downloading super_image-0.1.7-py3-none-any.whl (91 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: h5py>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from super_image) (3.8.0)\nRequirement already satisfied: huggingface-hub>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from super_image) (0.15.1)\nRequirement already satisfied: opencv-python>=4.5.2.54 in /opt/conda/lib/python3.10/site-packages (from super_image) (4.7.0.72)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from super_image) (2.0.0)\nRequirement already satisfied: torchvision>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from super_image) (0.15.1)\nRequirement already satisfied: tqdm>=4.61.2 in /opt/conda/lib/python3.10/site-packages (from super_image) (4.64.1)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.10/site-packages (from h5py>=3.1.0->super_image) (1.23.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.13->super_image) (3.12.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.13->super_image) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.13->super_image) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.13->super_image) (5.4.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.13->super_image) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.13->super_image) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->super_image) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->super_image) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->super_image) (3.1.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.10.0->super_image) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.0.13->super_image) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->super_image) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.0.13->super_image) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.0.13->super_image) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.0.13->super_image) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.0.13->super_image) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->super_image) (1.3.0)\nInstalling collected packages: super_image\nSuccessfully installed super_image-0.1.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from super_image.models.edsr.configuration_edsr import EdsrConfig\nfrom super_image.modeling_utils import (\n    default_conv,\n    MeanShift,\n    Upsampler,PreTrainedModel\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:22.221344Z","iopub.execute_input":"2023-06-30T09:09:22.221709Z","iopub.status.idle":"2023-06-30T09:09:22.622319Z","shell.execute_reply.started":"2023-06-30T09:09:22.221670Z","shell.execute_reply":"2023-06-30T09:09:22.621378Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Model ","metadata":{}},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    def __init__(\n            self, conv, n_feats, kernel_size,\n            bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n\n        super(ResBlock, self).__init__()\n        m = []\n        for i in range(2):\n            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n            if bn:\n                m.append(nn.BatchNorm2d(n_feats))\n            if i == 0:\n                m.append(act)\n\n        self.body = nn.Sequential(*m)\n        self.res_scale = res_scale\n\n    def forward(self, x):\n        res = self.body(x).mul(self.res_scale)\n        res += x\n\n        return res\n\n\nclass edsr(PreTrainedModel):\n    \n#     config_class = EdsrConfig\n    \n    def __init__(self, args, conv=default_conv):\n        super(edsr, self).__init__(args)\n\n        self.args = args\n        n_resblocks = args.n_resblocks\n        n_feats = args.n_feats\n        n_colors = args.n_colors\n        kernel_size = 3\n        scale = args.scale\n        rgb_range = args.rgb_range\n        act = nn.ReLU(True)\n        self.sub_mean = MeanShift(rgb_range, rgb_mean=args.rgb_mean, rgb_std=args.rgb_std)  # standardize input\n        self.add_mean = MeanShift(rgb_range, sign=1, rgb_mean=args.rgb_mean, rgb_std=args.rgb_std)  # restore output\n\n        # define head module, channels: 3->64\n        m_head = [conv(n_colors, n_feats, kernel_size)]\n\n        # define body module, channels: 64->64\n        m_body = [\n            ResBlock(\n                conv, n_feats, kernel_size, act=act, res_scale=args.res_scale\n            ) for _ in range(n_resblocks)\n        ]\n        m_body.append(conv(n_feats, n_feats, kernel_size))\n\n        self.head = nn.Sequential(*m_head)\n        self.body = nn.Sequential(*m_body)\n\n        if args.no_upsampling:\n            self.out_dim = n_feats\n        else:\n            self.out_dim = args.n_colors\n            # define tail module\n            m_tail = [\n                Upsampler(conv, scale, n_feats, act=False),\n                conv(n_feats, n_colors, kernel_size)\n            ]\n            self.tail = nn.Sequential(*m_tail)\n\n    def forward(self, x):\n        x = self.head(x)\n\n        res = self.body(x)\n        res += x\n\n        if self.args.no_upsampling:\n            x = res\n        else:\n            x = self.tail(res)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:22.623927Z","iopub.execute_input":"2023-06-30T09:09:22.624295Z","iopub.status.idle":"2023-06-30T09:09:22.640266Z","shell.execute_reply.started":"2023-06-30T09:09:22.624263Z","shell.execute_reply":"2023-06-30T09:09:22.639247Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:22.645060Z","iopub.execute_input":"2023-06-30T09:09:22.645765Z","iopub.status.idle":"2023-06-30T09:09:22.676640Z","shell.execute_reply.started":"2023-06-30T09:09:22.645730Z","shell.execute_reply":"2023-06-30T09:09:22.675897Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"# train_dir = 'data/train'\n# val_dir = 'data/validation'\n\n# train_transform = Compose([\n#                             Normalize([0.449, 0.438, 0.404],\n#                                       [1.0, 1.0, 1.0])])\n\n# valid_transform = Compose([\n#                             Normalize([0.440, 0.435, 0.403],\n#                                       [1.0, 1.0, 1.0])])\n\nt_set = load_dataset('eugenesiow/Div2k', 'bicubic_x2', split='train')\ne_set = load_dataset('eugenesiow/Div2k', 'bicubic_x2', split='validation')\n\n# trainset = TrainDataset(t_set, transform=train_transform)\n# validset = EvalDataset(e_set, transform=valid_transform)\n\n\n# trainset = DIV2K_x2(root_dir=train_dir, im_size=40, scale=2, transform=train_transforms)\n# validset = DIV2K_x2(root_dir=val_dir, im_size=40, scale=2, transform=valid_transforms)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:09:22.680838Z","iopub.execute_input":"2023-06-30T09:09:22.681611Z","iopub.status.idle":"2023-06-30T09:17:51.893445Z","shell.execute_reply.started":"2023-06-30T09:09:22.681574Z","shell.execute_reply":"2023-06-30T09:17:51.892557Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06704132c1c44913be932641946030a4"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset div2k/bicubic_x2 to /root/.cache/huggingface/datasets/eugenesiow___div2k/bicubic_x2/2.0.0/d7599f94c7e662a3eed3547efc7efa52b2ed71082b40fc2e42a693870e35b677...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e852bd0aad451392008e52dbae9c25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/925M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69e52f6c9a66426b93275d83b0abd14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/118M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a264b9d5d859480c8db715d5b8ec4f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"719e49d3c6354e068150c176fe75bedc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/449M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1589014823a444f381e95b86d2dbc10b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e202122e58f74924b56b83f097b01fda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset div2k downloaded and prepared to /root/.cache/huggingface/datasets/eugenesiow___div2k/bicubic_x2/2.0.0/d7599f94c7e662a3eed3547efc7efa52b2ed71082b40fc2e42a693870e35b677. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainset = TrainDataset(t_set)\nvalidset = EvalDataset(e_set)\n\ntrainloader = DataLoader(trainset, batch_size=8, shuffle=True)\nvalidloader = DataLoader(validset, batch_size=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:17:51.899587Z","iopub.execute_input":"2023-06-30T09:17:51.900302Z","iopub.status.idle":"2023-06-30T09:17:51.929298Z","shell.execute_reply.started":"2023-06-30T09:17:51.900268Z","shell.execute_reply":"2023-06-30T09:17:51.928235Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(epoch, model, optimizer):\n    \"\"\"\n    Save model checkpoint.\n    :param epoch: epoch number\n    :param model: model\n    :param optimizer: optimizer\n    \"\"\"\n    state = {'epoch': epoch,\n             'model': model,\n             'optimizer': optimizer}\n    filename = 'checkpoint.pth.tar'\n    torch.save(state, filename)\n    \ndef adjust_learning_rate(optimizer, scale):\n    \"\"\"\n    Scale learning rate by a specified factor.\n    :param optimizer: optimizer whose learning rate must be shrunk.\n    :param scale: factor to multiply learning rate with.\n    \"\"\"\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = param_group['lr'] * scale\n    print(\"DECAYING learning rate.\\n The new LR is %f\\n\" % (optimizer.param_groups[0]['lr'],))","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:17:51.931744Z","iopub.execute_input":"2023-06-30T09:17:51.932092Z","iopub.status.idle":"2023-06-30T09:17:52.729677Z","shell.execute_reply.started":"2023-06-30T09:17:51.932060Z","shell.execute_reply":"2023-06-30T09:17:52.728515Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"\n    Keeps track of most recent, average, sum, and count of a metric.\n    \"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:17:52.731083Z","iopub.execute_input":"2023-06-30T09:17:52.731592Z","iopub.status.idle":"2023-06-30T09:17:52.801752Z","shell.execute_reply.started":"2023-06-30T09:17:52.731559Z","shell.execute_reply":"2023-06-30T09:17:52.798331Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"criterion = nn.L1Loss()\nscale = 2\nepochs = 25\nprint_every = 5\ntrain_loss = 0\nbatch_num = 0\ndecay_lr_at = 11, 15   # decay learning rate after these many iterations\ndecay_lr_to = 0.1","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:39:06.847137Z","iopub.execute_input":"2023-06-30T09:39:06.847498Z","iopub.status.idle":"2023-06-30T09:39:06.853480Z","shell.execute_reply.started":"2023-06-30T09:39:06.847469Z","shell.execute_reply":"2023-06-30T09:39:06.852429Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from super_image.trainer_utils import EvalPrediction\nfrom super_image.utils.metrics import compute_metrics\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:39:07.349621Z","iopub.execute_input":"2023-06-30T09:39:07.350728Z","iopub.status.idle":"2023-06-30T09:39:07.355872Z","shell.execute_reply.started":"2023-06-30T09:39:07.350686Z","shell.execute_reply":"2023-06-30T09:39:07.354623Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"/kaggle/working/checkpoint.pth.tar\"\n\nbest_metric = 0\nbest_epoch = 0\n\ndef train(train_loader,valid_loader, model, criterion, optimizer, epoch):\n    \n    global best_metric, best_epoch\n    losses = AverageMeter()\n    \n    for i, (img, label) in enumerate(train_loader):\n        \n        start = time.time()\n\n        img, label = img.to(device), label.to(device)\n        pred = model(img)\n        # print(pred.shape, label.shape)\n        loss = criterion(pred, label)\n        \n        losses.update(loss.item(), img.size(0))\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Print status\n        if i % print_every == 0:\n            print('Epoch: [{0}][{1}/{2}]\\t'\n                  'Training Time {3:.3f} \\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(train_loader),\n                                                                  (time.time()-start)*print_every, loss=losses))\n\n    with torch.no_grad():\n        \n        model.eval()\n        val_losses = AverageMeter()\n        epoch_psnr = AverageMeter()\n        epoch_ssim = AverageMeter()\n        \n        for i, (val_inputs, val_labels) in enumerate(valid_loader):\n            \n            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n            val_preds = model(val_inputs)\n            val_loss = criterion(val_preds, val_labels)\n            \n            val_losses.update(val_loss.item(), val_inputs.size(0))\n            \n            metrics = compute_metrics(EvalPrediction(predictions=val_preds, labels=val_labels), scale=scale)\n\n            epoch_psnr.update(metrics['psnr'], val_inputs.size(0))\n            epoch_ssim.update(metrics['ssim'], val_inputs.size(0))\n\n        print(f'Validation Loss:{val_losses.avg:.2f}      eval psnr: {epoch_psnr.avg:.2f}     ssim: {epoch_ssim.avg:.4f}')\n\n        if epoch_psnr.avg > best_metric:\n            best_epoch = epoch\n            best_metric = epoch_psnr.avg\n\n            print(f'best epoch: {epoch}, psnr: {epoch_psnr.avg:.6f}, ssim: {epoch_ssim.avg:.6f}')\n            \n            # Save checkpoint\n            print(\"Saving checkpoint epoch:\", epoch)\n            save_checkpoint(epoch, model, optimizer)\n\n#         print('Epoch : {}/{}'.format(epoch_num, epochs))\n#         print('Training Loss : {:.4f}'.format(losses.avg))\n#         print('Validation Loss: {:.4f}'.format(val_losses.avg))","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:39:19.573610Z","iopub.execute_input":"2023-06-30T09:39:19.573993Z","iopub.status.idle":"2023-06-30T09:39:19.587690Z","shell.execute_reply.started":"2023-06-30T09:39:19.573943Z","shell.execute_reply":"2023-06-30T09:39:19.586223Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def main():\n    \"\"\"\n    Training.\n    \"\"\"\n    global start_epoch, label_map, epoch, checkpoint, decay_lr_at, optimizer, criterion, scale\n\n    # Initialize model or load checkpoint\n    if checkpoint is None:\n        config = EdsrConfig(\n        scale=scale,                               \n        n_resblocks=32,\n        n_feats=256\n    )\n        start_epoch = 0\n        model = edsr(config)\n        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n        \n    else:\n        checkpoint = torch.load(checkpoint)\n        start_epoch = checkpoint['epoch'] + 1\n        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n        model = checkpoint['model']\n        optimizer = checkpoint['optimizer']\n\n    # Move to default device\n    model = model.to(device)\n    criterion = criterion\n\n    print(\"Number of epochs: \", epochs)\n    \n    # Epochs\n    for epoch in range(start_epoch, epochs):\n\n        # Decay learning rate at particular epochs\n        if epoch in decay_lr_at:\n            adjust_learning_rate(optimizer, decay_lr_to)\n\n        # One epoch's training\n        train(train_loader=trainloader,\n              valid_loader = validloader,\n              model=model,\n              criterion=criterion,\n              optimizer=optimizer,\n              epoch=epoch)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:39:20.088939Z","iopub.execute_input":"2023-06-30T09:39:20.089299Z","iopub.status.idle":"2023-06-30T09:39:20.099941Z","shell.execute_reply.started":"2023-06-30T09:39:20.089271Z","shell.execute_reply":"2023-06-30T09:39:20.099053Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T09:39:20.750664Z","iopub.execute_input":"2023-06-30T09:39:20.751015Z","iopub.status.idle":"2023-06-30T10:09:32.298615Z","shell.execute_reply.started":"2023-06-30T09:39:20.750953Z","shell.execute_reply":"2023-06-30T10:09:32.297343Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\nLoaded checkpoint from epoch 22.\n\nNumber of epochs:  25\nDECAYING learning rate.\n The new LR is 0.000003\n\nEpoch: [22][0/100]\tTraining Time 1.264 \tLoss 0.0070 (0.0070)\t\nEpoch: [22][5/100]\tTraining Time 1.211 \tLoss 0.0229 (0.0164)\t\nEpoch: [22][10/100]\tTraining Time 1.210 \tLoss 0.0195 (0.0155)\t\nEpoch: [22][15/100]\tTraining Time 1.211 \tLoss 0.0192 (0.0158)\t\nEpoch: [22][20/100]\tTraining Time 1.215 \tLoss 0.0079 (0.0156)\t\nEpoch: [22][25/100]\tTraining Time 1.211 \tLoss 0.0098 (0.0154)\t\nEpoch: [22][30/100]\tTraining Time 1.212 \tLoss 0.0113 (0.0151)\t\nEpoch: [22][35/100]\tTraining Time 1.214 \tLoss 0.0078 (0.0149)\t\nEpoch: [22][40/100]\tTraining Time 1.208 \tLoss 0.0122 (0.0149)\t\nEpoch: [22][45/100]\tTraining Time 1.210 \tLoss 0.0117 (0.0147)\t\nEpoch: [22][50/100]\tTraining Time 1.210 \tLoss 0.0278 (0.0153)\t\nEpoch: [22][55/100]\tTraining Time 1.216 \tLoss 0.0171 (0.0154)\t\nEpoch: [22][60/100]\tTraining Time 1.210 \tLoss 0.0143 (0.0155)\t\nEpoch: [22][65/100]\tTraining Time 1.210 \tLoss 0.0145 (0.0154)\t\nEpoch: [22][70/100]\tTraining Time 1.209 \tLoss 0.0169 (0.0155)\t\nEpoch: [22][75/100]\tTraining Time 1.274 \tLoss 0.0149 (0.0156)\t\nEpoch: [22][80/100]\tTraining Time 1.212 \tLoss 0.0162 (0.0155)\t\nEpoch: [22][85/100]\tTraining Time 1.211 \tLoss 0.0095 (0.0154)\t\nEpoch: [22][90/100]\tTraining Time 1.215 \tLoss 0.0145 (0.0155)\t\nEpoch: [22][95/100]\tTraining Time 1.213 \tLoss 0.0133 (0.0156)\t\nValidation Loss:0.01      eval psnr: 34.78     ssim: 0.9345\nbest epoch: 22, psnr: 34.778187, ssim: 0.934548\nSaving checkpoint epoch: 22\nEpoch: [23][0/100]\tTraining Time 1.311 \tLoss 0.0160 (0.0160)\t\nEpoch: [23][5/100]\tTraining Time 1.210 \tLoss 0.0160 (0.0176)\t\nEpoch: [23][10/100]\tTraining Time 1.212 \tLoss 0.0173 (0.0156)\t\nEpoch: [23][15/100]\tTraining Time 1.211 \tLoss 0.0241 (0.0163)\t\nEpoch: [23][20/100]\tTraining Time 1.216 \tLoss 0.0141 (0.0160)\t\nEpoch: [23][25/100]\tTraining Time 1.211 \tLoss 0.0098 (0.0154)\t\nEpoch: [23][30/100]\tTraining Time 1.211 \tLoss 0.0089 (0.0149)\t\nEpoch: [23][35/100]\tTraining Time 1.214 \tLoss 0.0104 (0.0146)\t\nEpoch: [23][40/100]\tTraining Time 1.212 \tLoss 0.0082 (0.0144)\t\nEpoch: [23][45/100]\tTraining Time 1.212 \tLoss 0.0146 (0.0142)\t\nEpoch: [23][50/100]\tTraining Time 1.213 \tLoss 0.0218 (0.0147)\t\nEpoch: [23][55/100]\tTraining Time 1.210 \tLoss 0.0097 (0.0146)\t\nEpoch: [23][60/100]\tTraining Time 1.213 \tLoss 0.0317 (0.0149)\t\nEpoch: [23][65/100]\tTraining Time 1.212 \tLoss 0.0152 (0.0147)\t\nEpoch: [23][70/100]\tTraining Time 1.210 \tLoss 0.0095 (0.0145)\t\nEpoch: [23][75/100]\tTraining Time 1.245 \tLoss 0.0199 (0.0148)\t\nEpoch: [23][80/100]\tTraining Time 1.212 \tLoss 0.0158 (0.0147)\t\nEpoch: [23][85/100]\tTraining Time 1.213 \tLoss 0.0156 (0.0149)\t\nEpoch: [23][90/100]\tTraining Time 1.210 \tLoss 0.0054 (0.0147)\t\nEpoch: [23][95/100]\tTraining Time 1.211 \tLoss 0.0117 (0.0147)\t\nValidation Loss:0.01      eval psnr: 34.79     ssim: 0.9347\nbest epoch: 23, psnr: 34.785183, ssim: 0.934652\nSaving checkpoint epoch: 23\nEpoch: [24][0/100]\tTraining Time 1.244 \tLoss 0.0164 (0.0164)\t\nEpoch: [24][5/100]\tTraining Time 1.238 \tLoss 0.0154 (0.0163)\t\nEpoch: [24][10/100]\tTraining Time 1.211 \tLoss 0.0260 (0.0160)\t\nEpoch: [24][15/100]\tTraining Time 1.215 \tLoss 0.0146 (0.0146)\t\nEpoch: [24][20/100]\tTraining Time 1.212 \tLoss 0.0098 (0.0154)\t\nEpoch: [24][25/100]\tTraining Time 1.214 \tLoss 0.0098 (0.0147)\t\nEpoch: [24][30/100]\tTraining Time 1.209 \tLoss 0.0231 (0.0149)\t\nEpoch: [24][35/100]\tTraining Time 1.216 \tLoss 0.0076 (0.0147)\t\nEpoch: [24][40/100]\tTraining Time 1.210 \tLoss 0.0221 (0.0151)\t\nEpoch: [24][45/100]\tTraining Time 1.213 \tLoss 0.0077 (0.0152)\t\nEpoch: [24][50/100]\tTraining Time 1.215 \tLoss 0.0136 (0.0154)\t\nEpoch: [24][55/100]\tTraining Time 1.214 \tLoss 0.0215 (0.0154)\t\nEpoch: [24][60/100]\tTraining Time 1.213 \tLoss 0.0155 (0.0155)\t\nEpoch: [24][65/100]\tTraining Time 1.214 \tLoss 0.0180 (0.0155)\t\nEpoch: [24][70/100]\tTraining Time 1.211 \tLoss 0.0140 (0.0156)\t\nEpoch: [24][75/100]\tTraining Time 1.209 \tLoss 0.0085 (0.0156)\t\nEpoch: [24][80/100]\tTraining Time 1.210 \tLoss 0.0160 (0.0155)\t\nEpoch: [24][85/100]\tTraining Time 1.210 \tLoss 0.0233 (0.0156)\t\nEpoch: [24][90/100]\tTraining Time 1.213 \tLoss 0.0100 (0.0154)\t\nEpoch: [24][95/100]\tTraining Time 1.216 \tLoss 0.0157 (0.0156)\t\nValidation Loss:0.01      eval psnr: 34.79     ssim: 0.9347\nbest epoch: 24, psnr: 34.785301, ssim: 0.934664\nSaving checkpoint epoch: 24\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T10:09:54.904748Z","iopub.execute_input":"2023-06-30T10:09:54.905128Z","iopub.status.idle":"2023-06-30T10:09:55.124192Z","shell.execute_reply.started":"2023-06-30T10:09:54.905097Z","shell.execute_reply":"2023-06-30T10:09:55.123225Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\n\n!tar -czf checkpoint.pth.tar \n\nfrom IPython.display import FileLink\n\nFileLink(r'checkpoint.pth.tar')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T10:09:56.348149Z","iopub.execute_input":"2023-06-30T10:09:56.348512Z","iopub.status.idle":"2023-06-30T10:09:57.426129Z","shell.execute_reply.started":"2023-06-30T10:09:56.348475Z","shell.execute_reply":"2023-06-30T10:09:57.424982Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"tar: Cowardly refusing to create an empty archive\nTry 'tar --help' or 'tar --usage' for more information.\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/checkpoint.pth.tar","text/html":"<a href='checkpoint.pth.tar' target='_blank'>checkpoint.pth.tar</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}